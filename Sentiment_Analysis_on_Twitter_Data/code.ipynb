Step 1: Set up the environment
Install Required Libraries

!pip install tweepy
!pip install nltk
!pip install vaderSentiment
!pip install scikit-learn


Import Necessary Libraries
import tweepy
import pandas as pd
import numpy as np
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
import nltk
nltk.download('vader_lexicon')


Step 2: Twitter API Setup
Get Twitter API Keys
Sign up for a Twitter Developer account and get your API keys.

Authenticate Twitter API
# Replace these with your own Twitter API keys
consumer_key = 'your_consumer_key'
consumer_secret = 'your_consumer_secret'
access_token = 'your_access_token'
access_token_secret = 'your_access_token_secret'

# Authenticate with Tweepy
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)
api = tweepy.API(auth)

Step 3: Fetch Real-time Tweets
def fetch_tweets(query, count=100):
    tweets = api.search(q=query, lang="en", count=count)
    tweet_data = []
    for tweet in tweets:
        tweet_data.append(tweet.text)
    return pd.DataFrame(tweet_data, columns=['tweets'])

# Example: Fetch 100 tweets related to 'Face Mask'
df = fetch_tweets('Face Mask', 100)
df.head()

Step 4: Sentiment Analysis with VADER

# Initialize VADER sentiment analyzer
analyzer = SentimentIntensityAnalyzer()

# Function to classify sentiment
def get_sentiment(text):
    score = analyzer.polarity_scores(text)
    if score['compound'] >= 0.05:
        return 'Positive'
    elif score['compound'] <= -0.05:
        return 'Negative'
    else:
        return 'Neutral'

# Apply sentiment analysis to each tweet
df['sentiment'] = df['tweets'].apply(get_sentiment)
df.head()


Step 5: Preprocessing and Model Training
Vectorize Tweets
# Convert tweets to feature vectors using CountVectorizer
vectorizer = CountVectorizer(stop_words='english', max_features=1000)
X = vectorizer.fit_transform(df['tweets']).toarray()

# Sentiment labels (0 = Negative, 1 = Neutral, 2 = Positive)
df['sentiment_label'] = df['sentiment'].map({'Negative': 0, 'Neutral': 1, 'Positive': 2})
y = df['sentiment_label']


Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

Train Logistic Regression Model

model = LogisticRegression()
model.fit(X_train, y_train)

Step 6: Evaluate the Model

# Predict sentiment on the test set
y_pred = model.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.4f}')

# Print classification report
print(classification_report(y_test, y_pred))

Step 7: Save the Model

import pickle

# Save the trained model
with open('sentiment_model.pkl', 'wb') as file:
    pickle.dump(model, file)

# Save the vectorizer
with open('vectorizer.pkl', 'wb') as file:
    pickle.dump(vectorizer, file)
